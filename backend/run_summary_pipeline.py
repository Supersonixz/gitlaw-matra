import json
import os
import logging
from google import genai
from google.genai import types
from config import GOOGLE_API_KEY, CATEGORIES
from agents import AgentSummarizer

# --- Config ---
# ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô finalize (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà Clean ‡πÅ‡∏•‡πâ‡∏ß)
INPUT_FILE = "json_output/final/con2475_final.json"
# ‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ + ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà + ‡∏™‡∏£‡∏∏‡∏õ)
OUTPUT_FILE = "json_output/final/con2475_full_summary.json"

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

if not GOOGLE_API_KEY:
    raise ValueError("‚ùå GOOGLE_API_KEY is missing!")

client = genai.Client(api_key=GOOGLE_API_KEY)


def categorize_sections_with_ai(sections):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà: ‡∏™‡πà‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI ‡πÅ‡∏¢‡∏Å 18 ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    """
    logging.info(f"ü§ñ Categorizing {len(sections)} sections...")

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏á AI (‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà id ‡∏Å‡∏±‡∏ö content ‡∏û‡∏≠)
    sections_lite = [{"id": s["id"], "content": s["content"]} for s in sections]
    categories_text = "\n".join([f"- {k}: {v}" for k, v in CATEGORIES.items()])

    prompt = f"""
    Role: Thai Constitutional Law Expert.
    Task: Classify each legal section into exactly one of the provided 18 categories.
    
    Categories:
    {categories_text}
    
    Input Data (JSON):
    {json.dumps(sections_lite, ensure_ascii=False)}
    
    Instructions:
    1. Analyze the content of each section.
    2. Map section 'id' to the most appropriate 'category_id'.
    3. Return ONLY a JSON object mapping IDs to Categories.
    
    Output Example:
    {{
        "1": "general",
        "2": "monarchy",
        "65": "transitory"
    }}
    """

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config=types.GenerateContentConfig(response_mime_type="application/json"),
        )

        # ‡πÅ‡∏Å‡∏∞ JSON
        text = response.text.strip()
        if text.startswith("```json"):
            text = text[7:-3]
        return json.loads(text)

    except Exception as e:
        logging.error(f"‚ùå Categorization Failed: {e}")
        return {}


def generate_summaries_from_data(sections, year, output_path):
    """
    (‡∏¢‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å Code ‡πÄ‡∏Å‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) Logic ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°
    """
    agent_summarizer = AgentSummarizer()
    logging.info(f"‚ö° Generating Summaries for Year {year}...")

    # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Grouping)
    grouped_content_for_ai = {}
    grouped_sections_raw = {}

    for section in sections:
        cat_id = section.get("category_id", "uncategorized")

        # Init list
        if cat_id not in grouped_content_for_ai:
            grouped_content_for_ai[cat_id] = []
            grouped_sections_raw[cat_id] = []

        # ‡πÄ‡∏Å‡πá‡∏ö Text ‡πÉ‡∏´‡πâ AI (‡πÉ‡∏™‡πà‡πÄ‡∏•‡∏Ç‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢)
        text_with_ref = f"[‡∏°.{section.get('section_number')}] {section.get('content')}"
        grouped_content_for_ai[cat_id].append(text_with_ref)

        # ‡πÄ‡∏Å‡πá‡∏ö Object ‡∏î‡∏¥‡∏ö
        grouped_sections_raw[cat_id].append(section)

    # 2. ‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡πâ Agent (AI ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Batch Summary)
    logging.info("üß† Sending grouped content to AgentSummarizer...")
    ai_results_dict = agent_summarizer.run_batch(grouped_content_for_ai)

    if not ai_results_dict:
        logging.error("‚ùå No summary data returned from AI.")
        return

    # 3. ‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á (Merge)
    final_output_list = []

    for cat_id, cat_name in CATEGORIES.items():
        if cat_id not in grouped_content_for_ai:
            continue

        ai_data = ai_results_dict.get(cat_id, {})
        logging.info(
            f"   > Processed: {cat_name} ({len(grouped_sections_raw[cat_id])} sections)"
        )

        final_output_list.append(
            {
                "constitution_year": year,
                "category_id": cat_id,
                "category_name": cat_name,
                "ai_summary": ai_data.get("summary", "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ"),
                "key_change": ai_data.get("key_change", "-"),
                "section_count": len(grouped_sections_raw[cat_id]),
                "sections": grouped_sections_raw.get(cat_id, []),
            }
        )

    # Save
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(final_output_list, f, ensure_ascii=False, indent=2)

    logging.info(f"‚úÖ Success! Full summary saved to: {output_path}")


def main():
    if not os.path.exists(INPUT_FILE):
        logging.error(f"‚ùå Input file not found: {INPUT_FILE}")
        return

    # 1. Load Data (Clean JSON)
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        clean_sections = json.load(f)

    logging.info(f"üìÇ Loaded {len(clean_sections)} sections from clean JSON.")

    # 2. AI Categorize (‡∏ï‡∏¥‡∏î‡∏õ‡πâ‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà)
    category_map = categorize_sections_with_ai(clean_sections)

    # 3. Transform Data (‡πÅ‡∏õ‡∏•‡∏á‡∏£‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö Code ‡πÄ‡∏Å‡πà‡∏≤)
    ready_sections = []
    for item in clean_sections:
        sec_id = str(item["id"])

        # Mapping Fields
        new_item = {
            "section_number": sec_id,  # id -> section_number
            "content": item["content"],  # content -> content
            "category_id": category_map.get(sec_id, "general"),  # ‡πÉ‡∏™‡πà‡∏´‡∏°‡∏ß‡∏î‡∏ó‡∏µ‡πà AI ‡∏ö‡∏≠‡∏Å‡∏°‡∏≤
        }
        ready_sections.append(new_item)

    # 4. Run Summary Pipeline (‡∏™‡πà‡∏á‡πÑ‡∏°‡πâ‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤)
    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏µ 2475 (‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏Å‡πá‡πÑ‡∏î‡πâ)
    generate_summaries_from_data(ready_sections, 2475, OUTPUT_FILE)


if __name__ == "__main__":
    main()
